import streamlit as st
import pandas as pd
import plotly.express as px
from pymongo import MongoClient
from datetime import datetime
import plotly.graph_objects as go
from dotenv import load_dotenv
import os
import logging

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from html import escape

import unicodedata
import re

def clean_text(text):
    """Ê∏ÖÈô§ÊéßÂà∂Â≠óÁ¨¶Âπ∂ËΩ¨‰πâ HTMLÔºåÈÅøÂÖçÈùûÊ≥ïÂ≠óÁ¨¶ÂØºËá¥Ê∏≤ÊüìÂ¥©Ê∫É„ÄÇ"""
    if pd.isna(text):
        return ""
    try:
        text = str(text)
        text = unicodedata.normalize("NFKD", text)
        text = re.sub(r"[\x00-\x1f\x7f-\x9f]", "", text)  # Âà†Èô§ÊéßÂà∂Â≠óÁ¨¶
        text = escape(text)  # HTML ËΩ¨‰πâ
        return text
    except Exception as e:
        logger.warning(f"Failed to clean text: {text} ‚Äî {e}")
        return ""

def render_custom_table(df):
    styles = """
    <style>
    table {
        width: 100%;
        border-collapse: collapse;
        font-size: 14px;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        vertical-align: top;
        text-align: left;
        word-break: break-word;
    }
    th {
        background-color: #f2f2f2;
    }
    .narrow {
        width: 60px;
        text-align: right;
    }
    .wide-text {
        max-width: 600px;
    }
    </style>
    """

    columns = ['creation_date', 'text', 'issue_type', 'category', 'keyword', 'retweet_count', 'favorite_count']
    table_html = "<table><thead><tr>"
    for col in columns:
        table_html += f"<th>{escape(col)}</th>"
    table_html += "</tr></thead><tbody>"

    for _, row in df.iterrows():
        table_html += "<tr>"
        for col in columns:
            if col == 'creation_date' and isinstance(row[col], pd.Timestamp):
                val = row[col].strftime('%Y-%m-%d %H:%M')
            else:
                val = clean_text(row[col])
            class_attr = ""
            if col == 'text':
                class_attr = 'class="wide-text"'
            elif col in ['retweet_count', 'favorite_count']:
                class_attr = 'class="narrow"'
            table_html += f"<td {class_attr}>{val}</td>"
        table_html += "</tr>"

    table_html += "</tbody></table>"
    st.markdown(styles + table_html, unsafe_allow_html=True)


def create_category_issue_table(df):
    # ÁªüËÆ°ÊØè‰∏™ category ÁöÑ unhandled Âíå mishandled Êï∞Èáè
    grouped = df.groupby(['category', 'issue_type']).size().unstack(fill_value=0)
    grouped = grouped.rename(columns={'unhandled': 'Unhandled', 'mishandled': 'Mishandled'})
    
    # ËÆ°ÁÆóÊÄªÊï∞
    grouped['Total'] = grouped.sum(axis=1)
    
    # ÁîüÊàêÁôæÂàÜÊØîÊñáÊú¨Âàó
    grouped['Unhandled'] = grouped.apply(lambda row: f"{row['Unhandled']} ({round(row['Unhandled'] / row['Total'] * 100, 1)}%)" if row['Total'] > 0 else "0 (0.0%)", axis=1)
    grouped['Mishandled'] = grouped.apply(lambda row: f"{row['Mishandled']} ({round(row['Mishandled'] / row['Total'] * 100, 1)}%)" if row['Total'] > 0 else "0 (0.0%)", axis=1)
    
    # ÈáçËÆæÁ¥¢Âºï„ÄÅË∞ÉÊï¥ÂàóÈ°∫Â∫è
    grouped = grouped.reset_index()[['category', 'Unhandled', 'Mishandled', 'Total']]
    
    return grouped


def create_today_hourly_category_plot(df):
    today = datetime.utcnow().date()
    today_str = today.strftime("%B %d, %Y")

    df_today = df[df['creation_date'].dt.date == today].copy()
    if df_today.empty:
        fig = go.Figure()
        fig.update_layout(title=f"No data by category for today ({today_str})",
                          xaxis_title="Hour",
                          yaxis_title="Issue Count")
        return fig

    df_today['hour'] = df_today['creation_date'].dt.hour

    # ÂàÜÁªÑËÆ°Êï∞
    hourly_cat = df_today.groupby(['hour', 'category']).size().reset_index(name='count')

    # Ë°•ÈΩêÂ∞èÊó∂Âíå category ÁªÑÂêà
    all_hours = pd.DataFrame({'hour': range(24)})
    all_cats = df_today['category'].dropna().unique()
    filled = pd.concat([
        all_hours.assign(category=cat)
        for cat in all_cats
    ])
    hourly_cat = pd.merge(filled, hourly_cat, how='left', on=['hour', 'category']).fillna(0)
    hourly_cat['count'] = hourly_cat['count'].astype(int)

    # ÁîªÂõæ
    fig = px.line(hourly_cat,
                  x='hour',
                  y='count',
                  color='category',
                  markers=True,
                  title=f"Hourly Category Flow for Today ({today_str})",
                  labels={'hour': 'Hour of Day', 'count': 'Number of Issues'})

    fig.update_layout(xaxis=dict(tickmode='linear', dtick=1),
                      yaxis_range=[0, hourly_cat['count'].max() + 1])
    return fig


def connect_mongodb():
    uri = os.getenv("MONGO_URI")
    if not uri:
        raise ValueError("MONGO_URI environment variable not set")
    return MongoClient(uri)

def load_data():
    client = connect_mongodb()
    db = client["tiktok"]
    
    # Âä†ËΩΩ‰∏§‰∏™‰∏ªË¶ÅÈóÆÈ¢òÈõÜÂêà
    unhandled = list(db["unhandled_issues"].find())
    mishandled = list(db["mishandled_issues"].find())
    
    # ËΩ¨Êç¢‰∏∫DataFrame
    df_unhandled = pd.DataFrame(unhandled)
    df_mishandled = pd.DataFrame(mishandled)
    
    # Ê∑ªÂä†ÈóÆÈ¢òÁ±ªÂûãÊ†áËÆ∞
    df_unhandled['issue_type'] = 'unhandled'
    df_mishandled['issue_type'] = 'mishandled'
    
    # ÂêàÂπ∂Êï∞ÊçÆ
    df = pd.concat([df_unhandled, df_mishandled])
    
    # ËΩ¨Êç¢Êó•ÊúüÊ†ºÂºè
    if 'creation_date' in df.columns:
        df['creation_date'] = pd.to_datetime(df['creation_date'])
        # Âè™‰øùÁïô‰∫îÊúàÁöÑÊï∞ÊçÆ
        # df = df[df['creation_date'].dt.month == 5]
    
    return df

def create_today_hourly_flow_plot(df):
    # Ëé∑Âèñ‰ªäÂ§©ÁöÑÊó•ÊúüÔºàUTCÔºâ
    today = datetime.utcnow().date()
    today_str = today.strftime("%B %d, %Y")  # e.g., May 04, 2025

    # Âè™ÈÄâÂèñ‰ªäÂ§©ÁöÑÊï∞ÊçÆ
    df_today = df[df['creation_date'].dt.date == today].copy()

    if df_today.empty:
        fig = go.Figure()
        fig.update_layout(title=f"No data for today ({today_str})",
                          xaxis_title="Hour",
                          yaxis_title="Issue Count")
        return fig

    # ÊèêÂèñÂ∞èÊó∂Â≠óÊÆµ
    df_today['hour'] = df_today['creation_date'].dt.hour

    # ÊåâÂ∞èÊó∂ÂíåÁ±ªÂûãÂàÜÁªÑÁªüËÆ°Êï∞Èáè
    hourly_counts = df_today.groupby(['hour', 'issue_type']).size().reset_index(name='count')

    # Ë°•ÈΩê0-23Â∞èÊó∂ÁöÑÁ©∫ÂÄº
    all_hours = pd.DataFrame({'hour': range(24)})
    all_types = df_today['issue_type'].unique()
    filled = pd.concat([
        all_hours.assign(issue_type=issue_type)
        for issue_type in all_types
    ])
    hourly_counts = pd.merge(filled, hourly_counts, how='left', on=['hour', 'issue_type']).fillna(0)
    hourly_counts['count'] = hourly_counts['count'].astype(int)

    # ÁªòÂõæ
    fig = px.line(hourly_counts,
                  x='hour',
                  y='count',
                  color='issue_type',
                  markers=True,
                  title=f"Hourly Issue Flow for Today ({today_str})",
                  labels={'hour': 'Hour of Day', 'count': 'Number of Issues'})

    fig.update_layout(xaxis=dict(tickmode='linear', dtick=1),
                      yaxis_range=[0, hourly_counts['count'].max() + 1])
    return fig


def analyze_issue_distribution(df):
    # 1. ‰∏§ÁßçÈóÆÈ¢òÁ±ªÂûãÁöÑÊØî‰æã
    issue_type_counts = df['issue_type'].value_counts()
    
    # 2. ÂêÑÂàÜÁ±ªÁöÑÊØî‰æã
    category_counts = df['category'].value_counts()
    
    return issue_type_counts, category_counts

def create_time_series_plot(df):
    # ÊåâÊó•ÊúüÂíåÈóÆÈ¢òÁ±ªÂûãÁªüËÆ°
    daily_counts = df.groupby(['creation_date', 'issue_type']).size().reset_index(name='count')
    
    fig = px.line(daily_counts, 
                  x='creation_date', 
                  y='count', 
                  color='issue_type',
                  title='Daily Issue Counts by Type',
                  labels={'creation_date': 'Date', 
                         'count': 'Number of Issues'})
    
    # ËÆæÁΩÆyËΩ¥‰ªé0ÂºÄÂßã
    fig.update_layout(yaxis_range=[0, daily_counts['count'].max() + 1])
    
    return fig

def create_category_time_series_plot(df):
    df['date'] = df['creation_date'].dt.date
    all_dates = pd.date_range(df['date'].min(), df['date'].max()).date
    all_cats = df['category'].dropna().unique()

    # ÊûÑÈÄ†ÂÖ®ÈáèÊó•Êúü √ó category Á¨õÂç°Â∞îÁßØ
    full_grid = pd.MultiIndex.from_product([all_dates, all_cats], names=['date', 'category']).to_frame(index=False)

    # ÂÆûÈôÖÁªüËÆ°
    counts = df.groupby(['date', 'category']).size().reset_index(name='count')
    merged = pd.merge(full_grid, counts, on=['date', 'category'], how='left').fillna(0)
    merged['count'] = merged['count'].astype(int)

    # Âä†ÂÖ•ÊÄªÊï∞‰∏éÁôæÂàÜÊØî
    total_per_day = merged.groupby('date')['count'].sum().reset_index(name='total')
    merged = pd.merge(merged, total_per_day, on='date')
    merged['percentage'] = (merged['count'] / merged['total'] * 100).round(2)
    merged['percentage'] = merged['percentage'].fillna(0)

    # ÁîªÂõæ
    fig = px.line(
        merged,
        x='date',
        y='percentage',
        color='category',
        title='Daily Issue Category Proportion (%)',
        labels={'date': 'Date', 'percentage': 'Proportion (%)'},
        hover_data={'count': True, 'percentage': True, 'total': True}
    )

    # Ê∑ªÂä†Ë≠¶ÊàíÁ∫ø
    for y in [80, 20]:
        fig.add_shape(
            type="line",
            x0=merged['date'].min(),
            x1=merged['date'].max(),
            y0=y,
            y1=y,
            line=dict(color="red", width=1, dash="dash"),
            xref="x",
            yref="y"
        )
        fig.add_annotation(
            x=merged['date'].max(),
            y=y,
            text=f"{y}%",
            showarrow=False,
            yanchor="bottom" if y == 80 else "top",
            font=dict(color="red", size=12)
        )

    fig.update_layout(yaxis_range=[0, 100])
    return fig




def create_daily_summary_table(df):
    # Á°Æ‰øùÊó•ÊúüÊ†ºÂºèÊ≠£Á°Æ
    df['creation_date'] = pd.to_datetime(df['creation_date']).dt.date
    
    # ÊåâÊó•ÊúüÂàÜÁªÑËøõË°åÁªüËÆ°
    daily_summary = []
    
    for date, group in df.groupby('creation_date'):
        # ËÆ°ÁÆóËØ•Êó•ÊúüÁöÑÁªüËÆ°Êï∞ÊçÆ
        unhandled_count = (group['issue_type'] == 'unhandled').sum()
        mishandled_count = (group['issue_type'] == 'mishandled').sum()
        total_count = len(group)
        
        # ÁªüËÆ°ËØ•Êó•ÊúüÁöÑÂàÜÁ±ªÂàÜÂ∏É
        category_dist = group['category'].value_counts().to_dict()
        category_str = ", ".join([f"{k}: {v}" for k, v in category_dist.items()])
        
        # Ê∑ªÂä†Âà∞ÁªìÊûúÂàóË°®
        daily_summary.append({
            'Date': date.strftime('%Y-%m-%d'),
            'Total Issues': total_count,
            'Unhandled Issues': unhandled_count,
            'Mishandled Issues': mishandled_count,
            'Category Distribution': category_str
        })
    
    # ËΩ¨Êç¢‰∏∫DataFrame
    daily_summary_df = pd.DataFrame(daily_summary)
    
    # ÊåâÊó•ÊúüÊéíÂ∫è
    daily_summary_df = daily_summary_df.sort_values('Date')
    
    return daily_summary_df

def create_daily_time_series_plot(df):
    df['date'] = df['creation_date'].dt.date
    all_dates = pd.date_range(df['date'].min(), df['date'].max()).date
    all_types = df['issue_type'].dropna().unique()

    # ÊûÑÈÄ†ÂÖ®ÈáèÊó∂Èó¥ √ó Á±ªÂûã Á¨õÂç°Â∞îÁßØ
    full_grid = pd.MultiIndex.from_product([all_dates, all_types], names=['date', 'issue_type']).to_frame(index=False)

    # ÂÆûÈôÖÊï∞ÈáèÁªüËÆ°
    counts = df.groupby(['date', 'issue_type']).size().reset_index(name='count')
    merged = pd.merge(full_grid, counts, on=['date', 'issue_type'], how='left').fillna(0)
    merged['count'] = merged['count'].astype(int)

    # ËÆ°ÁÆóÊØèÊó•ÊÄªÊï∞‰∏éÁôæÂàÜÊØî
    total_per_day = merged.groupby('date')['count'].sum().reset_index(name='total')
    merged = pd.merge(merged, total_per_day, on='date')
    merged['percentage'] = (merged['count'] / merged['total'] * 100).round(2)
    merged['percentage'] = merged['percentage'].fillna(0)

    # ÁîªÂõæ
    fig = px.line(
        merged,
        x='date',
        y='percentage',
        color='issue_type',
        title='Daily Issue Type Proportion (%)',
        labels={'date': 'Date', 'percentage': 'Proportion (%)'},
        hover_data={'count': True, 'percentage': True, 'total': True}
    )

    # Ê∑ªÂä† 80% Âíå 20% ÁöÑË≠¶ÊàíÁ∫ø
    for y in [80, 20]:
        fig.add_shape(
            type="line",
            x0=merged['date'].min(),
            x1=merged['date'].max(),
            y0=y,
            y1=y,
            line=dict(color="red", width=1, dash="dash"),
            xref="x",
            yref="y"
        )
        fig.add_annotation(
            x=merged['date'].max(),
            y=y,
            text=f"{y}%",
            showarrow=False,
            yanchor="bottom" if y == 80 else "top",
            font=dict(color="red", size=12)
        )

    fig.update_layout(yaxis_range=[0, 100])
    return fig




def create_category_raw_count_plot(df):
    df['date'] = df['creation_date'].dt.date
    daily_category_counts = df.groupby(['date', 'category']).size().reset_index(name='count')
    fig = px.line(daily_category_counts, 
                  x='date', 
                  y='count', 
                  color='category',
                  title='Daily Issue Category Raw Count',
                  labels={'date': 'Date', 'count': 'Number of Issues'})
    fig.update_layout(yaxis_range=[0, daily_category_counts['count'].max() + 1])
    return fig



def create_daily_type_count_plot(df):
    df['date'] = df['creation_date'].dt.date

    # ÊâÄÊúâÊó•Êúü + ÊâÄÊúâÁ±ªÂûãÁöÑÁ¨õÂç°Â∞îÁßØ
    all_dates = pd.date_range(df['date'].min(), df['date'].max()).date
    all_types = df['issue_type'].dropna().unique()
    full_grid = pd.MultiIndex.from_product([all_dates, all_types], names=['date', 'issue_type']).to_frame(index=False)

    # ÂÆûÈôÖËÆ°Êï∞
    counts = df.groupby(['date', 'issue_type']).size().reset_index(name='count')

    # ÂêàÂπ∂Âπ∂Ë°•Èõ∂
    merged = pd.merge(full_grid, counts, on=['date', 'issue_type'], how='left').fillna(0)
    merged['count'] = merged['count'].astype(int)

    # ÁîªÂõæ
    fig = px.line(
        merged,
        x='date',
        y='count',
        color='issue_type',
        title='Daily Issue Type Trend (Raw Count)',
        labels={'date': 'Date', 'count': 'Number of Issues'},
        hover_data={'count': True}
    )
    fig.update_layout(yaxis_range=[0, merged['count'].max() + 1])
    return fig


def create_daily_type_percentage_plot(df):
    daily_counts = df.groupby([df['creation_date'].dt.date, 'issue_type']).size().reset_index(name='count')
    daily_counts.columns = ['date', 'issue_type', 'count']

    total_per_day = daily_counts.groupby('date')['count'].sum().reset_index(name='total')
    merged = pd.merge(daily_counts, total_per_day, on='date')
    merged['percentage'] = (merged['count'] / merged['total'] * 100).round(2)

    fig = px.line(
        merged,
        x='date',
        y='percentage',
        color='issue_type',
        title='Daily Issue Type Trend (Percentage)',
        labels={'date': 'Date', 'percentage': 'Proportion (%)'},
        hover_data={'count': True, 'percentage': True, 'total': True}
    )
    fig.update_layout(yaxis_range=[0, 100])
    return fig


def main():
    st.set_page_config(layout="wide")
    st.title("TikTok Governance Issues Analysis (May 2024)")

    # ÂàùÂßãÂåñ session state
    if "issue_type" not in st.session_state:
        st.session_state.issue_type = 'All'
    if "category" not in st.session_state:
        st.session_state.category = 'All'
    if "generate_summary" not in st.session_state:
        st.session_state.generate_summary = False

    # Âä†ËΩΩÊï∞ÊçÆ
    df = load_data()

    # Êó•ÊúüËøáÊª§Âô®
    st.sidebar.header("Date Filter")
    if 'creation_date' not in df.columns:
        st.error("No 'creation_date' column found.")
        return

    min_date = df['creation_date'].min().date()
    max_date = df['creation_date'].max().date()
    date_range = st.sidebar.date_input(
        "Select Date Range",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date
    )

    # ËøáÊª§Êï∞ÊçÆ
    filtered_df = df[
        (df['creation_date'].dt.date >= date_range[0]) &
        (df['creation_date'].dt.date <= date_range[1])
    ]

    # ‰∏äÊñπÂõæË°®Âå∫Ôºà‰ªÖÈ°µÈù¢ÂàùÊ¨°Âä†ËΩΩÊàñÊó•ÊúüÂèòÂåñÊó∂ÊòæÁ§∫Ôºå‰∏çÂèó‰∏ãÊñπÁ≠õÈÄâË°®ÂçïÂΩ±ÂìçÔºâ
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Issue Type Distribution")
        issue_type_counts = filtered_df['issue_type'].value_counts()
        fig1 = px.pie(values=issue_type_counts.values, names=issue_type_counts.index,
                      title="Unhandled vs Mishandled Issues")
        st.plotly_chart(fig1)
    with col2:
        st.subheader("Category Distribution")
        category_counts = filtered_df['category'].value_counts()
        fig2 = px.pie(values=category_counts.values, names=category_counts.index,
                      title="Issue Categories")
        st.plotly_chart(fig2)

    st.subheader("Issue Breakdown Table by Category")
    category_table = create_category_issue_table(filtered_df)
    st.dataframe(category_table, use_container_width=True)

    # Êó∂Èó¥Ë∂ãÂäøÂõæ
    st.subheader("Issue Trends Analysis")
    col3, col4 = st.columns(2)
    with col3:
        st.markdown("**Daily Issue Type Distribution**")
        fig3 = create_daily_time_series_plot(filtered_df)
        st.plotly_chart(fig3, use_container_width=True)
    with col4:
        st.markdown("**Daily Category Distribution**")
        fig4 = create_category_time_series_plot(filtered_df)
        st.plotly_chart(fig4, use_container_width=True)
    # üëâ Êñ∞Â¢ûÔºöÂü∫‰∫é Raw Count ÁöÑÊó∂Èó¥ÊµÅÂõæ
    col5, col6 = st.columns(2)
    with col5:
        st.markdown("**Daily Issue Type Trend (Raw Count)**")
        fig_type_count = create_daily_type_count_plot(filtered_df)
        st.plotly_chart(fig_type_count, use_container_width=True)

    with col6:
        st.markdown("**Daily Category Trend (Raw Count)**")
        fig_cat_count = create_category_raw_count_plot(filtered_df)  # Â∑≤ÂÆö‰πâÔºåÊó†ÈúÄÈáçÂëΩÂêç
        st.plotly_chart(fig_cat_count, use_container_width=True)


    # ‰ªäÊó•ÂÆûÊó∂ÂõæË°®ÔºàÂÖ®ÈáèÊï∞ÊçÆÔºå‰∏çÂèóÁ≠õÈÄâÊéßÂà∂Ôºâ
    st.subheader("Today's Hourly Flow (Unfiltered)")
    col7, col8 = st.columns(2)

    with col7:
        st.markdown("**Hourly Issue Type Flow**")
        fig_today_flow = create_today_hourly_flow_plot(df)
        st.plotly_chart(fig_today_flow, use_container_width=True)

    with col8:
        st.markdown("**Hourly Category Flow**")
        fig_today_category_flow = create_today_hourly_category_plot(df)
        st.plotly_chart(fig_today_category_flow, use_container_width=True)

    # ‚úÖ ‰∏ãÊñπËøáÊª§Âå∫
    st.subheader("Detailed Issue Data")
    issue_type_options = ['All'] + sorted(filtered_df['issue_type'].dropna().unique().tolist())
    category_options = ['All'] + sorted(filtered_df['category'].dropna().unique().tolist())

    with st.form(key="filter_form"):
        issue_type_selection = st.selectbox("Select Issue Type", issue_type_options,
                                            index=issue_type_options.index(st.session_state.issue_type))
        category_selection = st.selectbox("Select Category", category_options,
                                          index=category_options.index(st.session_state.category))
        apply_clicked = st.form_submit_button("Apply Filters")

        if apply_clicked:
            st.session_state.issue_type = issue_type_selection
            st.session_state.category = category_selection
            st.session_state.generate_summary = True  # ‚¨ÖÔ∏è GPT ‰ºöÂú®ÂêéÁª≠Ëß¶Âèë

    # ‚úÖ Â∫îÁî®ËøáÊª§
    df_filtered_comments = filtered_df.copy()
    if st.session_state.issue_type != 'All':
        df_filtered_comments = df_filtered_comments[df_filtered_comments['issue_type'] == st.session_state.issue_type]
    if st.session_state.category != 'All':
        df_filtered_comments = df_filtered_comments[df_filtered_comments['category'] == st.session_state.category]


    if st.session_state.generate_summary:
        st.session_state.generate_summary = False  # Áî®ÂÆåÂç≥Ê∏ÖÈô§
        if not df_filtered_comments.empty:
            top_50 = df_filtered_comments.sort_values(by='favorite_count', ascending=False).head(50)
            summary_input = "\n\n".join([f"[{i+1}] {row['text'].strip()}" for i, row in top_50.iterrows()])
            with st.spinner("Sending to GPT..."):
                import openai
                openai.api_key = os.getenv("OPENAI_API_KEY")
                gpt_prompt = f"""
                You are a TikTok governance analyst, you are now writing an important report table based on the review you have received, as a excellent PM, you should summarize the top themes, identify the most frequently mentioned issues without loosing any details. Based on the following comments, only generate a governance detailed summary table with the following columns: Major Issue Category, Specific Detailed-Issues (with specific examples as detailed as possible), Risk Analysis with rating from 1 to 5 and potential impact. ONLY generate a detailed table, do NOT generate anything else:
                {summary_input}
                """.strip()
                response = openai.ChatCompletion.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": gpt_prompt}],
                    temperature=0.5
                )
                gpt_output = response.choices[0].message['content']
                st.markdown("### üß† GPT Summary")
                st.markdown(gpt_output)

    st.subheader("Detailed Tweets")
    df_display = df_filtered_comments.copy()
    df_display['text'] = df_display['text'].apply(lambda x: x.replace('\n', ' ').strip())
    df_display = df_display.sort_values(by='creation_date', ascending=False)
    render_custom_table(df_display)






if __name__ == "__main__":
    main()
