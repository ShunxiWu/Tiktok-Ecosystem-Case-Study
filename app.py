import streamlit as st
import pandas as pd
import plotly.express as px
from pymongo import MongoClient
from datetime import datetime
import plotly.graph_objects as go
from dotenv import load_dotenv
import os
import logging

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from html import escape

import unicodedata
import re

def clean_text(text):
    """æ¸…é™¤æ§åˆ¶å­—ç¬¦å¹¶è½¬ä¹‰ HTMLï¼Œé¿å…éæ³•å­—ç¬¦å¯¼è‡´æ¸²æŸ“å´©æºƒã€‚"""
    if pd.isna(text):
        return ""
    if not isinstance(text, str):
        text = str(text)
    text = unicodedata.normalize("NFKD", text)                  # æ ‡å‡†åŒ–ä¸ºå…¼å®¹å½¢å¼
    text = re.sub(r"[\x00-\x1f\x7f-\x9f]", "", text)            # å»é™¤æ§åˆ¶å­—ç¬¦
    return escape(text)                                         # HTML è½¬ä¹‰

def render_custom_table(df):
    styles = """
    <style>
    table {
        width: 100%;
        border-collapse: collapse;
        font-size: 14px;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        vertical-align: top;
        text-align: left;
        word-break: break-word;
    }
    th {
        background-color: #f2f2f2;
    }
    .narrow {
        width: 60px;
        text-align: right;
    }
    .wide-text {
        max-width: 600px;
    }
    </style>
    """

    columns = ['creation_date', 'text', 'issue_type', 'category', 'keyword', 'retweet_count', 'favorite_count']
    table_html = "<table><thead><tr>"
    
    for col in columns:
        table_html += f"<th>{escape(str(col))}</th>"
    table_html += "</tr></thead><tbody>"

    for idx, row in df.iterrows():
        try:
            table_html += "<tr>"
            for col in columns:
                class_attr = ""
                if col == 'creation_date' and isinstance(row[col], pd.Timestamp):
                    val = row[col].strftime('%Y-%m-%d %H:%M')
                else:
                    val = clean_text(row.get(col, ""))

                if col == 'text':
                    class_attr = 'class="wide-text"'
                elif col in ['retweet_count', 'favorite_count']:
                    class_attr = 'class="narrow"'

                # æœ€åä¸€å±‚é˜²å¾¡ï¼šé¿å…éæ³•å­—ç¬¦å¹²æ‰° HTML æ¸²æŸ“
                val = escape(str(val)).replace('\x00', '')
                table_html += f"<td {class_attr}>{val}</td>"
            table_html += "</tr>"
        except Exception as e:
            logger.warning(f"Error rendering row {idx}: {e}")
            continue

    table_html += "</tbody></table>"

    # å¯é€‰ï¼šç§»é™¤ä»»ä½•ä¹±ç å­—ç¬¦
    try:
        table_html = table_html.encode('ascii', errors='ignore').decode()
    except:
        pass

    st.markdown(styles + table_html, unsafe_allow_html=True)


def create_category_issue_table(df):
    # ç»Ÿè®¡æ¯ä¸ª category çš„ unhandled å’Œ mishandled æ•°é‡
    grouped = df.groupby(['category', 'issue_type']).size().unstack(fill_value=0)
    grouped = grouped.rename(columns={'unhandled': 'Unhandled', 'mishandled': 'Mishandled'})
    
    # è®¡ç®—æ€»æ•°
    grouped['Total'] = grouped.sum(axis=1)
    
    # ç”Ÿæˆç™¾åˆ†æ¯”æ–‡æœ¬åˆ—
    grouped['Unhandled'] = grouped.apply(lambda row: f"{row['Unhandled']} ({round(row['Unhandled'] / row['Total'] * 100, 1)}%)" if row['Total'] > 0 else "0 (0.0%)", axis=1)
    grouped['Mishandled'] = grouped.apply(lambda row: f"{row['Mishandled']} ({round(row['Mishandled'] / row['Total'] * 100, 1)}%)" if row['Total'] > 0 else "0 (0.0%)", axis=1)
    
    # é‡è®¾ç´¢å¼•ã€è°ƒæ•´åˆ—é¡ºåº
    grouped = grouped.reset_index()[['category', 'Unhandled', 'Mishandled', 'Total']]
    
    return grouped


def create_today_hourly_category_plot(df):
    today = datetime.utcnow().date()
    today_str = today.strftime("%B %d, %Y")

    df_today = df[df['creation_date'].dt.date == today].copy()
    if df_today.empty:
        fig = go.Figure()
        fig.update_layout(title=f"No data by category for today ({today_str})",
                          xaxis_title="Hour",
                          yaxis_title="Issue Count")
        return fig

    df_today['hour'] = df_today['creation_date'].dt.hour

    # åˆ†ç»„è®¡æ•°
    hourly_cat = df_today.groupby(['hour', 'category']).size().reset_index(name='count')

    # è¡¥é½å°æ—¶å’Œ category ç»„åˆ
    all_hours = pd.DataFrame({'hour': range(24)})
    all_cats = df_today['category'].dropna().unique()
    filled = pd.concat([
        all_hours.assign(category=cat)
        for cat in all_cats
    ])
    hourly_cat = pd.merge(filled, hourly_cat, how='left', on=['hour', 'category']).fillna(0)
    hourly_cat['count'] = hourly_cat['count'].astype(int)

    # ç”»å›¾
    fig = px.line(hourly_cat,
                  x='hour',
                  y='count',
                  color='category',
                  markers=True,
                  title=f"Hourly Category Flow for Today ({today_str})",
                  labels={'hour': 'Hour of Day', 'count': 'Number of Issues'})

    fig.update_layout(xaxis=dict(tickmode='linear', dtick=1),
                      yaxis_range=[0, hourly_cat['count'].max() + 1])
    return fig


def connect_mongodb():
    uri = os.getenv("MONGO_URI")
    if not uri:
        raise ValueError("MONGO_URI environment variable not set")
    return MongoClient(uri)

def contains_illegal_char(value):
    try:
        if isinstance(value, dict):
            return any(contains_illegal_char(v) for v in value.values())
        elif isinstance(value, list):
            return any(contains_illegal_char(item) for item in value)
        elif isinstance(value, str):
            return '\uFFFD' in value
    except:
        return False
    return False

def clean_illegal_rows(df):
    def is_row_clean(row):
        for col in row.index:
            val = row[col]
            if contains_illegal_char(val):
                return False
        return True
    return df[df.apply(is_row_clean, axis=1)]

def load_data():
    client = connect_mongodb()
    db = client["tiktok"]

    # è®¾å®šéœ€è¦çš„å­—æ®µï¼ˆprojectionï¼‰
    projection = {
        '_id': 0,
        'creation_date': 1,
        'text': 1,
        'category': 1,
        'keyword': 1,
        'retweet_count': 1,
        'favorite_count': 1
    }

    # è®¾å®šæ—¥æœŸèŒƒå›´ï¼ˆ5æœˆ1æ—¥è‡³5æœˆ31æ—¥ï¼‰
    start_date = datetime(2025, 5, 1)
    end_date = datetime(2025, 5, 31, 23, 59, 59)

    # MongoDBæŸ¥è¯¢æ¡ä»¶
    query = {"creation_date": {"$gte": start_date, "$lte": end_date}}

    # åˆ†åˆ«æŸ¥è¯¢
    unhandled = list(db["unhandled_issues"].find(query, projection))
    mishandled = list(db["mishandled_issues"].find(query, projection))

    # è½¬æ¢ä¸º DataFrame å¹¶åŠ æ ‡ç­¾
    df_unhandled = pd.DataFrame(unhandled)
    df_mishandled = pd.DataFrame(mishandled)
    df_unhandled['issue_type'] = 'unhandled'
    df_mishandled['issue_type'] = 'mishandled'

    # åˆå¹¶
    df = pd.concat([df_unhandled, df_mishandled], ignore_index=True)

    # è½¬æ¢æ—¥æœŸ
    if 'creation_date' in df.columns:
        df['creation_date'] = pd.to_datetime(df['creation_date'], errors='coerce')

    # æ¸…ç†éæ³•å­—ç¬¦
    df = clean_illegal_rows(df)

    return df



def create_today_hourly_flow_plot(df):
    # è·å–ä»Šå¤©çš„æ—¥æœŸï¼ˆUTCï¼‰
    today = datetime.utcnow().date()
    today_str = today.strftime("%B %d, %Y")  # e.g., May 04, 2025

    # åªé€‰å–ä»Šå¤©çš„æ•°æ®
    df_today = df[df['creation_date'].dt.date == today].copy()

    if df_today.empty:
        fig = go.Figure()
        fig.update_layout(title=f"No data for today ({today_str})",
                          xaxis_title="Hour",
                          yaxis_title="Issue Count")
        return fig

    # æå–å°æ—¶å­—æ®µ
    df_today['hour'] = df_today['creation_date'].dt.hour

    # æŒ‰å°æ—¶å’Œç±»å‹åˆ†ç»„ç»Ÿè®¡æ•°é‡
    hourly_counts = df_today.groupby(['hour', 'issue_type']).size().reset_index(name='count')

    # è¡¥é½0-23å°æ—¶çš„ç©ºå€¼
    all_hours = pd.DataFrame({'hour': range(24)})
    all_types = df_today['issue_type'].unique()
    filled = pd.concat([
        all_hours.assign(issue_type=issue_type)
        for issue_type in all_types
    ])
    hourly_counts = pd.merge(filled, hourly_counts, how='left', on=['hour', 'issue_type']).fillna(0)
    hourly_counts['count'] = hourly_counts['count'].astype(int)

    # ç»˜å›¾
    fig = px.line(hourly_counts,
                  x='hour',
                  y='count',
                  color='issue_type',
                  markers=True,
                  title=f"Hourly Issue Flow for Today ({today_str})",
                  labels={'hour': 'Hour of Day', 'count': 'Number of Issues'})

    fig.update_layout(xaxis=dict(tickmode='linear', dtick=1),
                      yaxis_range=[0, hourly_counts['count'].max() + 1])
    return fig


def analyze_issue_distribution(df):
    # 1. ä¸¤ç§é—®é¢˜ç±»å‹çš„æ¯”ä¾‹
    issue_type_counts = df['issue_type'].value_counts()
    
    # 2. å„åˆ†ç±»çš„æ¯”ä¾‹
    category_counts = df['category'].value_counts()
    
    return issue_type_counts, category_counts

def create_time_series_plot(df):
    # æŒ‰æ—¥æœŸå’Œé—®é¢˜ç±»å‹ç»Ÿè®¡
    daily_counts = df.groupby(['creation_date', 'issue_type']).size().reset_index(name='count')
    
    fig = px.line(daily_counts, 
                  x='creation_date', 
                  y='count', 
                  color='issue_type',
                  title='Daily Issue Counts by Type',
                  labels={'creation_date': 'Date', 
                         'count': 'Number of Issues'})
    
    # è®¾ç½®yè½´ä»0å¼€å§‹
    fig.update_layout(yaxis_range=[0, daily_counts['count'].max() + 1])
    
    return fig

def create_category_time_series_plot(df):
    df['date'] = df['creation_date'].dt.date
    all_dates = pd.date_range(df['date'].min(), df['date'].max()).date
    all_cats = df['category'].dropna().unique()

    # æ„é€ å…¨é‡æ—¥æœŸ Ã— category ç¬›å¡å°”ç§¯
    full_grid = pd.MultiIndex.from_product([all_dates, all_cats], names=['date', 'category']).to_frame(index=False)

    # å®é™…ç»Ÿè®¡
    counts = df.groupby(['date', 'category']).size().reset_index(name='count')
    merged = pd.merge(full_grid, counts, on=['date', 'category'], how='left').fillna(0)
    merged['count'] = merged['count'].astype(int)

    # åŠ å…¥æ€»æ•°ä¸ç™¾åˆ†æ¯”
    total_per_day = merged.groupby('date')['count'].sum().reset_index(name='total')
    merged = pd.merge(merged, total_per_day, on='date')
    merged['percentage'] = (merged['count'] / merged['total'] * 100).round(2)
    merged['percentage'] = merged['percentage'].fillna(0)

    # ç”»å›¾
    fig = px.line(
        merged,
        x='date',
        y='percentage',
        color='category',
        title='Daily Issue Category Proportion (%)',
        labels={'date': 'Date', 'percentage': 'Proportion (%)'},
        hover_data={'count': True, 'percentage': True, 'total': True}
    )

    # æ·»åŠ è­¦æˆ’çº¿
    for y in [80, 20]:
        fig.add_shape(
            type="line",
            x0=merged['date'].min(),
            x1=merged['date'].max(),
            y0=y,
            y1=y,
            line=dict(color="red", width=1, dash="dash"),
            xref="x",
            yref="y"
        )
        fig.add_annotation(
            x=merged['date'].max(),
            y=y,
            text=f"{y}%",
            showarrow=False,
            yanchor="bottom" if y == 80 else "top",
            font=dict(color="red", size=12)
        )

    fig.update_layout(yaxis_range=[0, 100])
    return fig




def create_daily_summary_table(df):
    # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
    df['creation_date'] = pd.to_datetime(df['creation_date']).dt.date
    
    # æŒ‰æ—¥æœŸåˆ†ç»„è¿›è¡Œç»Ÿè®¡
    daily_summary = []
    
    for date, group in df.groupby('creation_date'):
        # è®¡ç®—è¯¥æ—¥æœŸçš„ç»Ÿè®¡æ•°æ®
        unhandled_count = (group['issue_type'] == 'unhandled').sum()
        mishandled_count = (group['issue_type'] == 'mishandled').sum()
        total_count = len(group)
        
        # ç»Ÿè®¡è¯¥æ—¥æœŸçš„åˆ†ç±»åˆ†å¸ƒ
        category_dist = group['category'].value_counts().to_dict()
        category_str = ", ".join([f"{k}: {v}" for k, v in category_dist.items()])
        
        # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
        daily_summary.append({
            'Date': date.strftime('%Y-%m-%d'),
            'Total Issues': total_count,
            'Unhandled Issues': unhandled_count,
            'Mishandled Issues': mishandled_count,
            'Category Distribution': category_str
        })
    
    # è½¬æ¢ä¸ºDataFrame
    daily_summary_df = pd.DataFrame(daily_summary)
    
    # æŒ‰æ—¥æœŸæ’åº
    daily_summary_df = daily_summary_df.sort_values('Date')
    
    return daily_summary_df

def create_daily_time_series_plot(df):
    df['date'] = df['creation_date'].dt.date
    all_dates = pd.date_range(df['date'].min(), df['date'].max()).date
    all_types = df['issue_type'].dropna().unique()

    # æ„é€ å…¨é‡æ—¶é—´ Ã— ç±»å‹ ç¬›å¡å°”ç§¯
    full_grid = pd.MultiIndex.from_product([all_dates, all_types], names=['date', 'issue_type']).to_frame(index=False)

    # å®é™…æ•°é‡ç»Ÿè®¡
    counts = df.groupby(['date', 'issue_type']).size().reset_index(name='count')
    merged = pd.merge(full_grid, counts, on=['date', 'issue_type'], how='left').fillna(0)
    merged['count'] = merged['count'].astype(int)

    # è®¡ç®—æ¯æ—¥æ€»æ•°ä¸ç™¾åˆ†æ¯”
    total_per_day = merged.groupby('date')['count'].sum().reset_index(name='total')
    merged = pd.merge(merged, total_per_day, on='date')
    merged['percentage'] = (merged['count'] / merged['total'] * 100).round(2)
    merged['percentage'] = merged['percentage'].fillna(0)

    # ç”»å›¾
    fig = px.line(
        merged,
        x='date',
        y='percentage',
        color='issue_type',
        title='Daily Issue Type Proportion (%)',
        labels={'date': 'Date', 'percentage': 'Proportion (%)'},
        hover_data={'count': True, 'percentage': True, 'total': True}
    )

    # æ·»åŠ  80% å’Œ 20% çš„è­¦æˆ’çº¿
    for y in [80, 20]:
        fig.add_shape(
            type="line",
            x0=merged['date'].min(),
            x1=merged['date'].max(),
            y0=y,
            y1=y,
            line=dict(color="red", width=1, dash="dash"),
            xref="x",
            yref="y"
        )
        fig.add_annotation(
            x=merged['date'].max(),
            y=y,
            text=f"{y}%",
            showarrow=False,
            yanchor="bottom" if y == 80 else "top",
            font=dict(color="red", size=12)
        )

    fig.update_layout(yaxis_range=[0, 100])
    return fig




def create_category_raw_count_plot(df):
    df['date'] = df['creation_date'].dt.date
    daily_category_counts = df.groupby(['date', 'category']).size().reset_index(name='count')
    fig = px.line(daily_category_counts, 
                  x='date', 
                  y='count', 
                  color='category',
                  title='Daily Issue Category Raw Count',
                  labels={'date': 'Date', 'count': 'Number of Issues'})
    fig.update_layout(yaxis_range=[0, daily_category_counts['count'].max() + 1])
    return fig



def create_daily_type_count_plot(df):
    df['date'] = df['creation_date'].dt.date

    # æ‰€æœ‰æ—¥æœŸ + æ‰€æœ‰ç±»å‹çš„ç¬›å¡å°”ç§¯
    all_dates = pd.date_range(df['date'].min(), df['date'].max()).date
    all_types = df['issue_type'].dropna().unique()
    full_grid = pd.MultiIndex.from_product([all_dates, all_types], names=['date', 'issue_type']).to_frame(index=False)

    # å®é™…è®¡æ•°
    counts = df.groupby(['date', 'issue_type']).size().reset_index(name='count')

    # åˆå¹¶å¹¶è¡¥é›¶
    merged = pd.merge(full_grid, counts, on=['date', 'issue_type'], how='left').fillna(0)
    merged['count'] = merged['count'].astype(int)

    # ç”»å›¾
    fig = px.line(
        merged,
        x='date',
        y='count',
        color='issue_type',
        title='Daily Issue Type Trend (Raw Count)',
        labels={'date': 'Date', 'count': 'Number of Issues'},
        hover_data={'count': True}
    )
    fig.update_layout(yaxis_range=[0, merged['count'].max() + 1])
    return fig


def create_daily_type_percentage_plot(df):
    daily_counts = df.groupby([df['creation_date'].dt.date, 'issue_type']).size().reset_index(name='count')
    daily_counts.columns = ['date', 'issue_type', 'count']

    total_per_day = daily_counts.groupby('date')['count'].sum().reset_index(name='total')
    merged = pd.merge(daily_counts, total_per_day, on='date')
    merged['percentage'] = (merged['count'] / merged['total'] * 100).round(2)

    fig = px.line(
        merged,
        x='date',
        y='percentage',
        color='issue_type',
        title='Daily Issue Type Trend (Percentage)',
        labels={'date': 'Date', 'percentage': 'Proportion (%)'},
        hover_data={'count': True, 'percentage': True, 'total': True}
    )
    fig.update_layout(yaxis_range=[0, 100])
    return fig


def main():
    st.set_page_config(layout="wide")
    st.title("TikTok Governance Issues Analysis (May 2025)")

    # åˆå§‹åŒ– session state
    if "issue_type" not in st.session_state:
        st.session_state.issue_type = 'All'
    if "category" not in st.session_state:
        st.session_state.category = 'All'
    if "generate_summary" not in st.session_state:
        st.session_state.generate_summary = False

    # åŠ è½½æ•°æ®
    df = load_data()

    # æ—¥æœŸè¿‡æ»¤å™¨
    st.sidebar.header("Date Filter")
    if 'creation_date' not in df.columns:
        st.error("No 'creation_date' column found.")
        return

    min_date = datetime(2025, 5, 1).date()
    max_date = datetime(2025, 5, 31).date()
    date_range = st.sidebar.date_input(
        "Select Date Range",
        value=(min_date, max_date),
        min_value=min_date,
        max_value=max_date
    )

    # è¿‡æ»¤æ•°æ®
    filtered_df = df[
        (df['creation_date'].dt.date >= date_range[0]) &
        (df['creation_date'].dt.date <= date_range[1])
    ]

    # ä¸Šæ–¹å›¾è¡¨åŒºï¼ˆä»…é¡µé¢åˆæ¬¡åŠ è½½æˆ–æ—¥æœŸå˜åŒ–æ—¶æ˜¾ç¤ºï¼Œä¸å—ä¸‹æ–¹ç­›é€‰è¡¨å•å½±å“ï¼‰
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Issue Type Distribution")
        issue_type_counts = filtered_df['issue_type'].value_counts()
        fig1 = px.pie(values=issue_type_counts.values, names=issue_type_counts.index,
                      title="Unhandled vs Mishandled Issues")
        st.plotly_chart(fig1)
    with col2:
        st.subheader("Category Distribution")
        category_counts = filtered_df['category'].value_counts()
        fig2 = px.pie(values=category_counts.values, names=category_counts.index,
                      title="Issue Categories")
        st.plotly_chart(fig2)

    st.subheader("Issue Breakdown Table by Category")
    category_table = create_category_issue_table(filtered_df)
    st.dataframe(category_table, use_container_width=True)

    # æ—¶é—´è¶‹åŠ¿å›¾
    st.subheader("Issue Trends Analysis")
    col3, col4 = st.columns(2)
    with col3:
        st.markdown("**Daily Issue Type Distribution**")
        fig3 = create_daily_time_series_plot(filtered_df)
        st.plotly_chart(fig3, use_container_width=True)
    with col4:
        st.markdown("**Daily Category Distribution**")
        fig4 = create_category_time_series_plot(filtered_df)
        st.plotly_chart(fig4, use_container_width=True)
    # ğŸ‘‰ æ–°å¢ï¼šåŸºäº Raw Count çš„æ—¶é—´æµå›¾
    col5, col6 = st.columns(2)
    with col5:
        st.markdown("**Daily Issue Type Trend (Raw Count)**")
        fig_type_count = create_daily_type_count_plot(filtered_df)
        st.plotly_chart(fig_type_count, use_container_width=True)

    with col6:
        st.markdown("**Daily Category Trend (Raw Count)**")
        fig_cat_count = create_category_raw_count_plot(filtered_df)  # å·²å®šä¹‰ï¼Œæ— éœ€é‡å‘½å
        st.plotly_chart(fig_cat_count, use_container_width=True)


    # ä»Šæ—¥å®æ—¶å›¾è¡¨ï¼ˆå…¨é‡æ•°æ®ï¼Œä¸å—ç­›é€‰æ§åˆ¶ï¼‰
    st.subheader("Today's Hourly Flow (Unfiltered)")
    col7, col8 = st.columns(2)

    with col7:
        st.markdown("**Hourly Issue Type Flow**")
        fig_today_flow = create_today_hourly_flow_plot(df)
        st.plotly_chart(fig_today_flow, use_container_width=True)

    with col8:
        st.markdown("**Hourly Category Flow**")
        fig_today_category_flow = create_today_hourly_category_plot(df)
        st.plotly_chart(fig_today_category_flow, use_container_width=True)

    # âœ… ä¸‹æ–¹è¿‡æ»¤åŒº
    st.subheader("Detailed Issue Data")
    issue_type_options = ['All'] + sorted(filtered_df['issue_type'].dropna().unique().tolist())
    category_options = ['All'] + sorted(filtered_df['category'].dropna().unique().tolist())

    with st.form(key="filter_form"):
        issue_type_selection = st.selectbox("Select Issue Type", issue_type_options,
                                            index=issue_type_options.index(st.session_state.issue_type))
        category_selection = st.selectbox("Select Category", category_options,
                                          index=category_options.index(st.session_state.category))
        apply_clicked = st.form_submit_button("Apply Filters")

        if apply_clicked:
            st.session_state.issue_type = issue_type_selection
            st.session_state.category = category_selection
            st.session_state.generate_summary = True  # â¬…ï¸ GPT ä¼šåœ¨åç»­è§¦å‘

    # âœ… åº”ç”¨è¿‡æ»¤
    df_filtered_comments = filtered_df.copy()
    if st.session_state.issue_type != 'All':
        df_filtered_comments = df_filtered_comments[df_filtered_comments['issue_type'] == st.session_state.issue_type]
    if st.session_state.category != 'All':
        df_filtered_comments = df_filtered_comments[df_filtered_comments['category'] == st.session_state.category]

    # âœ… GPT æ‘˜è¦ä»…åœ¨ç‚¹å‡»æŒ‰é’®åè¿è¡Œä¸€æ¬¡
    if st.session_state.generate_summary:
        st.session_state.generate_summary = False  # ç”¨å®Œå³æ¸…é™¤
        if not df_filtered_comments.empty:
            top_50 = df_filtered_comments.sort_values(by='favorite_count', ascending=False).head(50)
            summary_input = "\n\n".join([f"[{i+1}] {row['text'].strip()}" for i, row in top_50.iterrows()])
            with st.spinner("Sending to GPT..."):
                import openai
                openai.api_key = os.getenv("OPENAI_API_KEY")
                gpt_prompt = f"""
                You are a TikTok governance analyst, you are now writing an important report table based on the review you have received, as a excellent PM, you should summarize the top themes, identify the most frequently mentioned issues without loosing any details. Based on the following comments, only generate a governance detailed summary table with the following columns: Major Issue Category, Specific Detailed-Issues (with specific examples as detailed as possible), Risk Analysis with rating from 1 to 5 and potential impact. ONLY generate a detailed table, do NOT generate anything else:
                {summary_input}
                """.strip()
                response = openai.ChatCompletion.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": gpt_prompt}],
                    temperature=0.5
                )
                gpt_output = response.choices[0].message['content']
                st.markdown("### ğŸ§  GPT Summary")
                st.markdown(gpt_output)

    # âœ… æ¸²æŸ“æœ€ç»ˆè¡¨æ ¼ï¼ˆå§‹ç»ˆæ˜¾ç¤ºï¼‰
    st.subheader("Detailed Tweets")
    df_display = df_filtered_comments.copy()
    df_display['text'] = df_display['text'].apply(lambda x: x.replace('\n', ' ').strip())
    df_display = df_display.sort_values(by='creation_date', ascending=False)
    render_custom_table(df_display)






if __name__ == "__main__":
    main()
